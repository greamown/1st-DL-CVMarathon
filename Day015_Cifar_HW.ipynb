{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True) \n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 1.7160 - acc: 0.5098\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.0374 - acc: 0.6395\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.9335 - acc: 0.6752\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.8782 - acc: 0.69176s - loss: 0.8618 - acc: 0.69 - ETA: 6s - loss: 0.861 -  - ETA: 1s - loss: 0.8\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.8432 - acc: 0.7067\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.8026 - acc: 0.72050s - loss: 0.8036 - acc: 0\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.7737 - acc: 0.7306\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.7475 - acc: 0.7395\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.7231 - acc: 0.7483\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.7002 - acc: 0.75682s - loss: 0.6910 -  - ETA: 1s - loss: \n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.6798 - acc: 0.7651\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.6622 - acc: 0.7675\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.6451 - acc: 0.7767\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.6302 - acc: 0.7807\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.6173 - acc: 0.7837\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 0.6021 - acc: 0.7885\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.5942 - acc: 0.7934\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.5818 - acc: 0.7957\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.5747 - acc: 0.79840s - loss: 0.5745 - ac\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.5621 - acc: 0.8011\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.5522 - acc: 0.8051\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.5444 - acc: 0.80670s - loss: 0.5443 - acc: 0.8\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.5344 - acc: 0.8108\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.5275 - acc: 0.8118\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.5213 - acc: 0.81701s - loss: 0.5\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.5114 - acc: 0.8194\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.5057 - acc: 0.8204\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.5018 - acc: 0.82070s - loss: 0.5004 - acc: \n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.4925 - acc: 0.8249\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.4853 - acc: 0.8274\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.4839 - acc: 0.8288\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.4742 - acc: 0.8305\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.4724 - acc: 0.8307\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.4651 - acc: 0.8348\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.4620 - acc: 0.83491s - los\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.4574 - acc: 0.8369TA: \n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.4517 - acc: 0.8386\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.4489 - acc: 0.8385\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.4389 - acc: 0.8440\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.4396 - acc: 0.84336 - ETA: - ETA: 2s - loss: 0.4311  - ETA: 1s -\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.4349 - acc: 0.8439\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.4348 - acc: 0.844 - 9s 179us/step - loss: 0.4351 - acc: 0.8444\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.4282 - acc: 0.8467\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.4213 - acc: 0.8494\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.4212 - acc: 0.8502\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.4167 - acc: 0.8507\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.4163 - acc: 0.8514\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 0.4114 - acc: 0.8519\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.4072 - acc: 0.8531\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.4031 - acc: 0.8561\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.4023 - acc: 0.8558\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.3973 - acc: 0.8564\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.3957 - acc: 0.8586\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.3915 - acc: 0.8604\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.3930 - acc: 0.8597\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.3868 - acc: 0.8618\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.3829 - acc: 0.8636\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.3797 - acc: 0.8630\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.3801 - acc: 0.8626\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.3787 - acc: 0.8634\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.3743 - acc: 0.8654\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.3722 - acc: 0.8646\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.3742 - acc: 0.8656\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.3681 - acc: 0.8668\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3647 - acc: 0.8696\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.3637 - acc: 0.8683\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.3597 - acc: 0.8718\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3604 - acc: 0.8697\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3581 - acc: 0.8711\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.3563 - acc: 0.8706\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.3514 - acc: 0.8725\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3490 - acc: 0.8734\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.3507 - acc: 0.8722\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3470 - acc: 0.8744 1s - loss:\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3472 - acc: 0.8727 0s - loss: 0.3467 - ac\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3441 - acc: 0.8763 0s - loss: 0.3440 - acc:\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3402 - acc: 0.8761\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3419 - acc: 0.8772\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3398 - acc: 0.8779\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.3376 - acc: 0.8772\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3373 - acc: 0.8782\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3352 - acc: 0.8763\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3301 - acc: 0.8797 0s - loss: 0.3289 - acc: - ETA: 0s - loss: 0.3300 - acc: 0.879\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3368 - acc: 0.8782\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3294 - acc: 0.8810\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.3271 - acc: 0.8811\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.3241 - acc: 0.8826\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3234 - acc: 0.8825\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.3270 - acc: 0.8813\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3249 - acc: 0.8814\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.3204 - acc: 0.8833\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.3234 - acc: 0.8823\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3186 - acc: 0.8845\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3195 - acc: 0.8827\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.3188 - acc: 0.8840\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3146 - acc: 0.8862\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 0.3188 - acc: 0.8828\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.3151 - acc: 0.8852\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.3116 - acc: 0.8860\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.3086 - acc: 0.8883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22588d19c18>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,(3,3),padding= \"same\", input_shape =(32,32,3),activation=\"relu\"))\n",
    "#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(BatchNormalization())         \n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(512)) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation=\"softmax\"))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8414585e-04, 1.5229820e-05, 4.9626004e-02, 2.0472956e-01,\n",
       "        1.0324061e-02, 8.0031989e-04, 8.6594038e-02, 1.3789700e-04,\n",
       "        6.4738870e-01, 7.0774658e-10]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
