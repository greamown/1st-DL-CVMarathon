{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto(allow_soft_placement=True) \n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main():\n",
    "    annotation_path = '2007_train.txt' #待訓練清單(YOLO格式）\n",
    "    log_dir = 'logs/000/' #訓練過程及結果暫存路徑\n",
    "    classes_path = 'model_data/my_classes.txt' #自定義標籤檔路徑及名稱\n",
    "    anchors_path = 'model_data/yolo_anchors.txt' #錨點定義檔路徑及名稱\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw 預設輸入影像尺寸須為32的倍數(寬，高)\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/yolo_weights.h5') #指定起始訓練權重檔路徑及名稱\n",
    "        \n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3) #訓練過程權重檔名稱由第幾輪加上損失率為名稱\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1,mode='auto')\n",
    "\n",
    "    val_split = 0.1\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 1 #批次處理數量，依GPU記憶體大小決定\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=50, #訓練遍歷次數\n",
    "                initial_epoch=0, #初始訓練遍歷次數\n",
    "                callbacks=[logging, checkpoint])\n",
    "    \n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5') #儲存臨時權重檔案名稱\n",
    "\n",
    "    # 解凍並繼續訓練以進行微調\n",
    "    # 如果效果不好則訓練更長時間\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 1 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=100, #訓練遍歷次數\n",
    "            initial_epoch=50, #初始訓練遍歷次數\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        \n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5') #儲存最終權重檔\n",
    "        #model.save(log_dir + 'trained_model_final.h5') #儲存完整模型及權重檔\n",
    "\n",
    "    # Further training if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 2 classes.\n",
      "Load weights model_data/yolo_weights.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "Train on 108 samples, val on 12 samples, with batch size 1.\n",
      "Epoch 1/50\n",
      "108/108 [==============================] - 18s 170ms/step - loss: 1132.8628 - val_loss: 109.8321\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - 16s 148ms/step - loss: 87.5034 - val_loss: 56.6417\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - 14s 132ms/step - loss: 54.3917 - val_loss: 42.1694\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - 15s 140ms/step - loss: 42.0986 - val_loss: 34.3749\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - 15s 142ms/step - loss: 35.6892 - val_loss: 28.0455\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - 18s 163ms/step - loss: 31.0454 - val_loss: 28.2281\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - 15s 138ms/step - loss: 28.2883 - val_loss: 25.6547\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 27.3103 - val_loss: 25.0160\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 25.5274 - val_loss: 21.5315\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 24.4089 - val_loss: 22.4560\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 23.5764 - val_loss: 20.5886\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 24.4199 - val_loss: 19.1515\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 22.0327 - val_loss: 19.8065\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 21.9292 - val_loss: 20.0757\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 21.5348 - val_loss: 19.4899\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 21.6513 - val_loss: 18.6422\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 20.2499 - val_loss: 18.6054\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - 14s 132ms/step - loss: 21.1125 - val_loss: 17.7258\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 20.4245 - val_loss: 19.0156\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 20.2336 - val_loss: 20.5501\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 19.5371 - val_loss: 20.7036\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 20.0800 - val_loss: 21.6094\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - 14s 134ms/step - loss: 20.2586 - val_loss: 19.1064\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 19.2642 - val_loss: 18.5642\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 19.2424 - val_loss: 18.2674\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - 16s 144ms/step - loss: 19.0049 - val_loss: 17.9279\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - 15s 140ms/step - loss: 18.8344 - val_loss: 18.6877\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - 15s 141ms/step - loss: 19.1637 - val_loss: 19.7190\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 18.7153 - val_loss: 16.8258\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 19.1388 - val_loss: 19.1998\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - 14s 133ms/step - loss: 19.2808 - val_loss: 18.6660\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - 14s 133ms/step - loss: 18.8349 - val_loss: 19.1721\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - 15s 137ms/step - loss: 18.3890 - val_loss: 19.0311\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - 15s 138ms/step - loss: 19.8177 - val_loss: 18.1343\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - 14s 132ms/step - loss: 19.4378 - val_loss: 18.1032\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 18.6076 - val_loss: 17.8707\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 18.7369 - val_loss: 18.7024\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 18.4050 - val_loss: 18.8635\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 18.5983 - val_loss: 18.2470\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - 14s 128ms/step - loss: 18.0561 - val_loss: 18.9106\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 17.5552 - val_loss: 19.1278\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - 14s 130ms/step - loss: 18.2667 - val_loss: 16.7632\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 18.6441 - val_loss: 17.7835\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 18.6814 - val_loss: 19.0354\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 18.5859 - val_loss: 18.4644\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 18.6263 - val_loss: 16.1701\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 18.3401 - val_loss: 18.3772\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - 14s 131ms/step - loss: 17.5767 - val_loss: 16.7239\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 17.9389 - val_loss: 18.0709\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - 14s 129ms/step - loss: 17.4467 - val_loss: 18.6192\n",
      "Unfreeze all of the layers.\n",
      "Train on 108 samples, val on 12 samples, with batch size 1.\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 65s 601ms/step - loss: 20.1417 - val_loss: 18.1027\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 18.1288 - val_loss: 17.2621\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 17.3347 - val_loss: 16.2951\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 17.1842 - val_loss: 17.4095\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 16.9464 - val_loss: 17.1561\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 16.1704 - val_loss: 20.9223\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 15.3307 - val_loss: 17.3602\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 15.1638 - val_loss: 16.8723\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 52s 484ms/step - loss: 14.8349 - val_loss: 17.9343\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 52s 485ms/step - loss: 14.4132 - val_loss: 14.9957\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.3245 - val_loss: 14.6387\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.5313 - val_loss: 14.3654\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.4654 - val_loss: 15.8074\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.7357 - val_loss: 15.2241\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.6109 - val_loss: 16.3695\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.7747 - val_loss: 15.0321\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.1127 - val_loss: 15.9539\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 13.9375 - val_loss: 15.4580\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.0323 - val_loss: 14.4656\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.2065 - val_loss: 18.0558\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 15.0159 - val_loss: 13.9733\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 52s 483ms/step - loss: 14.2324 - val_loss: 16.5699\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.2024 - val_loss: 14.5993\n",
      "Epoch 74/100\n",
      "108/108 [==============================] - 53s 486ms/step - loss: 14.8793 - val_loss: 14.8592\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 52s 484ms/step - loss: 14.2471 - val_loss: 16.0455\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 52s 485ms/step - loss: 14.1447 - val_loss: 17.1170\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.3349 - val_loss: 16.4247\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 53s 486ms/step - loss: 14.2876 - val_loss: 15.7932\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 53s 489ms/step - loss: 14.5898 - val_loss: 15.7874\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.3536 - val_loss: 15.2063\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 52s 483ms/step - loss: 14.4077 - val_loss: 15.0199\n",
      "Epoch 00081: early stopping\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    _main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
